{"cells":[{"cell_type":"markdown","metadata":{"id":"gSbFti0yUlvj"},"source":["---\n","# IMPORTANT\n","\n","**Please remember to save this notebook `SC201L14.ipynb` as you work on it!**\n","\n","### 請大家務必在這份檔案中使用 GPU。\n","\n","請點選 `Runtime -> Change runtime type` 並將 `Hardware Accelerator` 設定為 `GPU`。"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"UvKceQDgUoy3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1687432361701,"user_tz":-480,"elapsed":22144,"user":{"displayName":"Kevin Tsai","userId":"03189192575775510032"}},"outputId":"6bc940b6-715b-41e0-c195-4b50cc9c7f9f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/MyDrive/Colab Notebooks/SC201L14/sc201/datasets\n","/content\n"]}],"source":["# this mounts your Google Drive to the Colab VM.\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","\n","# 請輸入 L14 資料夾之所在位置\n","FOLDERNAME = 'Colab\\ Notebooks/SC201L14'\n","assert FOLDERNAME is not None, \"[!] Enter the foldername.\"\n","\n","# now that we've mounted your Drive, this ensures that\n","# the Python interpreter of the Colab VM can load\n","# python files from within it.\n","import sys\n","sys.path.append('/content/drive/MyDrive/{}'.format(FOLDERNAME))\n","\n","# this downloads the CIFAR-10 dataset to your Drive\n","# if it doesn't already exist.\n","%cd drive/MyDrive/$FOLDERNAME/sc201/datasets/\n","!bash get_datasets.sh\n","%cd /content"]},{"cell_type":"markdown","metadata":{"id":"0J4P7Ce9Uoy4","tags":["pdf-title"]},"source":["# What is PyTorch?\n","\n","PyTorch 是一套計算系統，可以用來計算動態圖形 (neural network 是圖形的一種)。這些圖形是由 PyTorch 的 Tensor 物件組成的，Tensor 的用法如同 numpy 矩陣。PyTorch 內建自動微分的功能，使用者就不必手動處理 backward pass！\n","\n","This notebook assumes that you are using **PyTorch version 1.4+**\n","\n","## Why PyTorch?\n","\n","* PyTorch 支援 GPU 計算，我們的 training 就可以利用 GPU 執行，程式會跑的更快！\n","* PyTorch 也是使用 modular design，大家以後就可以直接使用 PyTorch 既有模組（或是自己定義）並隨意拼湊成各式各樣的 neural network！\n","* 學術和業界中的 machine learning 都是使用 PyTorch 或是其他類似的強大計算套件，大家也就能跟上最新的研究和應用！\n","\n","## How can I learn PyTorch on my own?\n","\n","有興趣可以參考網路上的 PyTorch 教學，如 https://github.com/jcjohnson/pytorch-examples\n","\n","另外也可以參考 PyTorch 的說明書 [API doc](http://pytorch.org/docs/stable/index.html)。PyTorch 相關問題會建議大家在 [PyTorch forum](https://discuss.pytorch.org/) 上發問，而非 StackOverflow。"]},{"cell_type":"markdown","metadata":{"id":"RF9UmYilUoy4"},"source":["# Section I. Preparation\n","\n","大家在之前的作業裡做 data preparation 都是呼叫我們提供的程式。\n","\n","PyTorch 內建的 `DataLoader` 和 `sampler` 類別可以將這個步驟自動化。詳細用法請參考以下的 code，特別是 data 的正規化 (normalization) 和分劃 (partitioning into *train / val / test*)。"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"bL-q1O0mUoy4","tags":["pdf-ignore"],"executionInfo":{"status":"ok","timestamp":1687432366754,"user_tz":-480,"elapsed":5056,"user":{"displayName":"Kevin Tsai","userId":"03189192575775510032"}}},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from torch.utils.data import DataLoader\n","from torch.utils.data import sampler\n","\n","import torchvision.datasets as dset\n","import torchvision.transforms as T\n","\n","import numpy as np"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"NZIFC1x2Uoy4","tags":["pdf-ignore"],"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1687432378020,"user_tz":-480,"elapsed":11270,"user":{"displayName":"Kevin Tsai","userId":"03189192575775510032"}},"outputId":"8a5fd3bc-325a-4d96-e819-4007f29cc8ac"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./sc201/datasets/cifar-10-python.tar.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 170498071/170498071 [00:05<00:00, 29637723.27it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting ./sc201/datasets/cifar-10-python.tar.gz to ./sc201/datasets\n","Files already downloaded and verified\n","Files already downloaded and verified\n"]}],"source":["NUM_TRAIN = 49000\n","\n","# The torchvision.transforms package provides tools for preprocessing data\n","# and for performing data augmentation; here we set up a transform to\n","# preprocess the data by subtracting the mean RGB value and dividing by the\n","# standard deviation of each RGB value; we've hardcoded the mean and std.\n","transform = T.Compose([\n","                T.ToTensor(),\n","                T.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n","            ])\n","\n","# We set up a Dataset object for each split (train / val / test); Datasets load\n","# training examples one at a time, so we wrap each Dataset in a DataLoader which\n","# iterates through the Dataset and forms minibatches. We divide the CIFAR-10\n","# training set into train and val sets by passing a Sampler object to the\n","# DataLoader telling how it should sample from the underlying Dataset.\n","cifar10_train = dset.CIFAR10('./sc201/datasets', train=True, download=True,\n","                             transform=transform)\n","loader_train = DataLoader(cifar10_train, batch_size=64,\n","                          sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN)))\n","\n","cifar10_val = dset.CIFAR10('./sc201/datasets', train=True, download=True,\n","                           transform=transform)\n","loader_val = DataLoader(cifar10_val, batch_size=64,\n","                        sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN, 50000)))\n","\n","cifar10_test = dset.CIFAR10('./sc201/datasets', train=False, download=True,\n","                            transform=transform)\n","loader_test = DataLoader(cifar10_test, batch_size=64)"]},{"cell_type":"markdown","metadata":{"id":"8HUBOP0GUoy4","tags":["pdf-ignore"]},"source":["我們透由 `device` 啟用 PyTorch 的 GPU 功能。\n","\n","（如果您未將 CUDA 開啟，`torch.cuda.is_available()` 會回傳 False，使 notebook 轉回 CPU mode。）"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"T0OcEnkAUoy4","tags":["pdf-ignore-input"],"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1687432378021,"user_tz":-480,"elapsed":8,"user":{"displayName":"Kevin Tsai","userId":"03189192575775510032"}},"outputId":"1a7484e4-42ee-4acd-b8a9-5b48b5888d88"},"outputs":[{"output_type":"stream","name":"stdout","text":["using device: cuda\n"]}],"source":["USE_GPU = True\n","\n","dtype = torch.float32 # we will be using float throughout this tutorial\n","\n","if USE_GPU and torch.cuda.is_available():\n","    device = torch.device('cuda')\n","else:\n","    device = torch.device('cpu')\n","\n","# Constant to control how frequently we print train loss\n","print_every = 100\n","\n","print('using device:', device)"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"hHEQMJjmd7IU","executionInfo":{"status":"ok","timestamp":1687432378021,"user_tz":-480,"elapsed":5,"user":{"displayName":"Kevin Tsai","userId":"03189192575775510032"}}},"outputs":[],"source":["def train_part34(model, optimizer, epochs=1):\n","    \"\"\"\n","    Train a model on CIFAR-10 using the PyTorch Module API.\n","\n","    Inputs:\n","    - model: A PyTorch Module giving the model to train.\n","    - optimizer: An Optimizer object we will use to train the model\n","    - epochs: (Optional) A Python integer giving the number of epochs to train for\n","\n","    Returns: Nothing, but prints model accuracies during training.\n","    \"\"\"\n","    model = model.to(device=device)  # move the model parameters to CPU/GPU\n","    for e in range(epochs):\n","        for t, (x, y) in enumerate(loader_train):\n","            model.train()  # put model to training mode\n","            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n","            y = y.to(device=device, dtype=torch.long)\n","\n","            scores = model(x)\n","            loss_function = nn.CrossEntropyLoss()\n","            loss = loss_function(scores, y)\n","\n","            # Zero out all of the gradients for the variables which the optimizer\n","            # will update.\n","            optimizer.zero_grad()\n","\n","            # This is the backwards pass: compute the gradient of the loss with\n","            # respect to each  parameter of the model.\n","            loss.backward()\n","\n","            # Actually update the parameters of the model using the gradients\n","            # computed by the backwards pass.\n","            optimizer.step()\n","\n","            if t % print_every == 0:\n","                print('Iteration %d, loss = %.4f' % (t, loss.item()))\n","                check_accuracy_part34(loader_val, model)\n","                print()"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"9Oa5NtYAezm0","executionInfo":{"status":"ok","timestamp":1687432378021,"user_tz":-480,"elapsed":4,"user":{"displayName":"Kevin Tsai","userId":"03189192575775510032"}}},"outputs":[],"source":["def check_accuracy_part34(loader, model):\n","    if loader.dataset.train:\n","        print('Checking accuracy on validation set')\n","    else:\n","        print('Checking accuracy on test set')\n","    num_correct = 0\n","    num_samples = 0\n","    model.eval()  # set model to evaluation mode\n","    with torch.no_grad():\n","        for x, y in loader:\n","            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n","            y = y.to(device=device, dtype=torch.long)\n","            scores = model(x)\n","            _, preds = scores.max(1)\n","            num_correct += (preds == y).sum()\n","            num_samples += preds.size(0)\n","        acc = float(num_correct) / num_samples\n","        print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))"]},{"cell_type":"markdown","metadata":{"id":"Zh5tqAb7Uoy5"},"source":["# PyTorch Sequential API\n","\n","### Sequential API: Two-Layer Network\n","以下是 two-layer fully connected network 的 `nn.Sequential` 範例，我們把內建的 layer 依序丟入，並使用同樣的 training loop 進行訓練。\n","\n","大家在這裡不用做 hyperparameter tuning，但是在不做 tuning 的情況下，模型應該還是能在一個 epoch 之內達到 40% 以上的準確率。"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"S8qx1q_XUoy5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1687432444746,"user_tz":-480,"elapsed":66729,"user":{"displayName":"Kevin Tsai","userId":"03189192575775510032"}},"outputId":"990784d3-a223-4070-df79-e2cfd10215b9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Iteration 0, loss = 2.3875\n","Checking accuracy on validation set\n","Got 140 / 1000 correct (14.00)\n","\n","Iteration 100, loss = 1.7819\n","Checking accuracy on validation set\n","Got 339 / 1000 correct (33.90)\n","\n","Iteration 200, loss = 1.6635\n","Checking accuracy on validation set\n","Got 401 / 1000 correct (40.10)\n","\n","Iteration 300, loss = 1.7745\n","Checking accuracy on validation set\n","Got 408 / 1000 correct (40.80)\n","\n","Iteration 400, loss = 1.9584\n","Checking accuracy on validation set\n","Got 402 / 1000 correct (40.20)\n","\n","Iteration 500, loss = 1.8865\n","Checking accuracy on validation set\n","Got 402 / 1000 correct (40.20)\n","\n","Iteration 600, loss = 1.6952\n","Checking accuracy on validation set\n","Got 456 / 1000 correct (45.60)\n","\n","Iteration 700, loss = 1.6894\n","Checking accuracy on validation set\n","Got 451 / 1000 correct (45.10)\n","\n","Iteration 0, loss = 1.5628\n","Checking accuracy on validation set\n","Got 453 / 1000 correct (45.30)\n","\n","Iteration 100, loss = 1.6852\n","Checking accuracy on validation set\n","Got 454 / 1000 correct (45.40)\n","\n","Iteration 200, loss = 1.8673\n","Checking accuracy on validation set\n","Got 425 / 1000 correct (42.50)\n","\n","Iteration 300, loss = 1.8681\n","Checking accuracy on validation set\n","Got 458 / 1000 correct (45.80)\n","\n","Iteration 400, loss = 1.7290\n","Checking accuracy on validation set\n","Got 436 / 1000 correct (43.60)\n","\n","Iteration 500, loss = 1.3965\n","Checking accuracy on validation set\n","Got 467 / 1000 correct (46.70)\n","\n","Iteration 600, loss = 1.8356\n","Checking accuracy on validation set\n","Got 448 / 1000 correct (44.80)\n","\n","Iteration 700, loss = 1.8652\n","Checking accuracy on validation set\n","Got 461 / 1000 correct (46.10)\n","\n","Iteration 0, loss = 1.8299\n","Checking accuracy on validation set\n","Got 451 / 1000 correct (45.10)\n","\n","Iteration 100, loss = 1.6811\n","Checking accuracy on validation set\n","Got 465 / 1000 correct (46.50)\n","\n","Iteration 200, loss = 1.6277\n","Checking accuracy on validation set\n","Got 483 / 1000 correct (48.30)\n","\n","Iteration 300, loss = 1.7990\n","Checking accuracy on validation set\n","Got 482 / 1000 correct (48.20)\n","\n","Iteration 400, loss = 1.6879\n","Checking accuracy on validation set\n","Got 482 / 1000 correct (48.20)\n","\n","Iteration 500, loss = 1.3880\n","Checking accuracy on validation set\n","Got 468 / 1000 correct (46.80)\n","\n","Iteration 600, loss = 1.6592\n","Checking accuracy on validation set\n","Got 445 / 1000 correct (44.50)\n","\n","Iteration 700, loss = 1.6741\n","Checking accuracy on validation set\n","Got 445 / 1000 correct (44.50)\n","\n"]}],"source":["# We need to wrap `flatten` function in a module in order to stack it\n","# in nn.Sequential\n","\n","hidden_layer_size = 4000\n","learning_rate = 1e-2\n","\n","model = nn.Sequential(\n","    nn.Flatten(),\n","    nn.Linear(3 * 32 * 32, hidden_layer_size),\n","    nn.ReLU(),\n","    nn.Linear(hidden_layer_size, 10),\n",")\n","\n","# you can use Nesterov momentum in optim.SGD\n","optimizer = optim.SGD(model.parameters(), lr=learning_rate,\n","                     momentum=0.9, nesterov=True)\n","\n","train_part34(model, optimizer, epochs=3)"]},{"cell_type":"markdown","metadata":{"id":"FjbPzAATUoy5"},"source":["### Sequential API: Three-Layer ConvNet\n","請大家使用 `nn.Sequential` 建立並訓練出一套 three-layer ConvNet，架構依舊是：\n","\n","1. Convolutional layer (with bias) with 32 3x3 filters, with zero-padding of 1\n","2. ReLU\n","3. Convolutional layer (with bias) with 16 3x3 filters, with zero-padding of 1\n","4. ReLU\n","5. Fully-connected layer (with bias) to compute scores for 10 classes\n","\n","訓練的方式請使用 stochastic gradient descent with Nesterov momentum 0.9。\n","\n","大家在這裡不用做 hyperparameter tuning，但是在不做 tuning 的情況下，模型應該還是能在一個 epoch 之內達到 55% 以上的準確率。"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"sequential_accuracy","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1687432507292,"user_tz":-480,"elapsed":62569,"user":{"displayName":"Kevin Tsai","userId":"03189192575775510032"}},"outputId":"43b75a48-7e71-4e24-d1ca-168179e15af6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Iteration 0, loss = 2.3021\n","Checking accuracy on validation set\n","Got 136 / 1000 correct (13.60)\n","\n","Iteration 100, loss = 1.5323\n","Checking accuracy on validation set\n","Got 430 / 1000 correct (43.00)\n","\n","Iteration 200, loss = 1.4150\n","Checking accuracy on validation set\n","Got 523 / 1000 correct (52.30)\n","\n","Iteration 300, loss = 1.2364\n","Checking accuracy on validation set\n","Got 559 / 1000 correct (55.90)\n","\n","Iteration 400, loss = 1.2008\n","Checking accuracy on validation set\n","Got 594 / 1000 correct (59.40)\n","\n","Iteration 500, loss = 1.2820\n","Checking accuracy on validation set\n","Got 582 / 1000 correct (58.20)\n","\n","Iteration 600, loss = 1.1548\n","Checking accuracy on validation set\n","Got 588 / 1000 correct (58.80)\n","\n","Iteration 700, loss = 1.0785\n","Checking accuracy on validation set\n","Got 631 / 1000 correct (63.10)\n","\n","Iteration 0, loss = 1.0637\n","Checking accuracy on validation set\n","Got 592 / 1000 correct (59.20)\n","\n","Iteration 100, loss = 0.8304\n","Checking accuracy on validation set\n","Got 631 / 1000 correct (63.10)\n","\n","Iteration 200, loss = 1.2584\n","Checking accuracy on validation set\n","Got 612 / 1000 correct (61.20)\n","\n","Iteration 300, loss = 1.1138\n","Checking accuracy on validation set\n","Got 641 / 1000 correct (64.10)\n","\n","Iteration 400, loss = 1.1175\n","Checking accuracy on validation set\n","Got 634 / 1000 correct (63.40)\n","\n","Iteration 500, loss = 0.8798\n","Checking accuracy on validation set\n","Got 650 / 1000 correct (65.00)\n","\n","Iteration 600, loss = 0.8355\n","Checking accuracy on validation set\n","Got 622 / 1000 correct (62.20)\n","\n","Iteration 700, loss = 1.0712\n","Checking accuracy on validation set\n","Got 661 / 1000 correct (66.10)\n","\n","Iteration 0, loss = 0.7788\n","Checking accuracy on validation set\n","Got 655 / 1000 correct (65.50)\n","\n","Iteration 100, loss = 0.9595\n","Checking accuracy on validation set\n","Got 655 / 1000 correct (65.50)\n","\n","Iteration 200, loss = 0.7686\n","Checking accuracy on validation set\n","Got 634 / 1000 correct (63.40)\n","\n","Iteration 300, loss = 0.8980\n","Checking accuracy on validation set\n","Got 648 / 1000 correct (64.80)\n","\n","Iteration 400, loss = 0.8373\n","Checking accuracy on validation set\n","Got 688 / 1000 correct (68.80)\n","\n","Iteration 500, loss = 0.8175\n","Checking accuracy on validation set\n","Got 647 / 1000 correct (64.70)\n","\n","Iteration 600, loss = 0.8313\n","Checking accuracy on validation set\n","Got 678 / 1000 correct (67.80)\n","\n","Iteration 700, loss = 0.9233\n","Checking accuracy on validation set\n","Got 675 / 1000 correct (67.50)\n","\n"]}],"source":["model = None\n","optimizer = None\n","\n","################################################################################\n","# TODO: Rewrite the 2-layer ConvNet with bias from Part III with the           #\n","# Sequential API.                                                              #\n","################################################################################\n","# *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n","\n","\n","#model = nn.Sequential(\n","#    # N x 3 x 32 x 32\n","#    nn.Conv2d(3,32,3,1,1),\n","#    nn.ReLU(),\n","\n","#    # N x 32 x 32 x 32\n","#    nn.Conv2d(32,16,3,1,1),\n","#    nn.ReLU(),\n","\n","#    # N x 16 x 32 x 32\n","#    nn.Flatten(),\n","#   nn.Linear(16 * 32 * 32,10)\n","\n","#)\n","\n","# with max pooling and BatchNorm2d\n","model = nn.Sequential(\n","    # N x 3 x 32 x 32\n","    # torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros', device=None, dtype=None)\n","    nn.Conv2d(3,32,3,1,1),\n","    nn.BatchNorm2d(32),\n","    nn.ReLU(),\n","    nn.MaxPool2d(2,2),\n","    # N x 32 x 16 x 16\n","    nn.Conv2d(32,16,3,1,1),\n","    nn.BatchNorm2d(16),\n","    nn.ReLU(),\n","    nn.MaxPool2d(2,2),\n","    # N x 16 x 8 x 8\n","\n","    nn.Flatten(),\n","    nn.Linear(16 * 8 * 8,100),\n","\n","    nn.ReLU(),\n","    nn.Linear(100,10)\n","\n",")\n","\n","\n","#optimizer = optim.SGD(model.parameters(), lr = learning_rate, momentum = 0.9, nesterov=True)\n","optimizer = optim.Adam(model.parameters(), lr = 1e-3)\n","\n","\n","# *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n","################################################################################\n","#                                 END OF YOUR CODE\n","################################################################################\n","\n","train_part34(model, optimizer, epochs=3)"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"edzWXJBshCc2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1687432507293,"user_tz":-480,"elapsed":25,"user":{"displayName":"Kevin Tsai","userId":"03189192575775510032"}},"outputId":"5f0e8f8a-c016-4775-c127-5ef4c6968c6b"},"outputs":[{"output_type":"stream","name":"stdout","text":["----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1           [-1, 32, 32, 32]             896\n","       BatchNorm2d-2           [-1, 32, 32, 32]              64\n","              ReLU-3           [-1, 32, 32, 32]               0\n","         MaxPool2d-4           [-1, 32, 16, 16]               0\n","            Conv2d-5           [-1, 16, 16, 16]           4,624\n","       BatchNorm2d-6           [-1, 16, 16, 16]              32\n","              ReLU-7           [-1, 16, 16, 16]               0\n","         MaxPool2d-8             [-1, 16, 8, 8]               0\n","           Flatten-9                 [-1, 1024]               0\n","           Linear-10                  [-1, 100]         102,500\n","             ReLU-11                  [-1, 100]               0\n","           Linear-12                   [-1, 10]           1,010\n","================================================================\n","Total params: 109,126\n","Trainable params: 109,126\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.01\n","Forward/backward pass size (MB): 0.92\n","Params size (MB): 0.42\n","Estimated Total Size (MB): 1.35\n","----------------------------------------------------------------\n"]}],"source":["from torchsummary import summary\n","summary(model, (3,32,32))"]},{"cell_type":"code","source":[],"metadata":{"id":"s1zmaHR0J8Wb","executionInfo":{"status":"ok","timestamp":1687432507294,"user_tz":-480,"elapsed":24,"user":{"displayName":"Kevin Tsai","userId":"03189192575775510032"}}},"execution_count":9,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"}},"nbformat":4,"nbformat_minor":0}